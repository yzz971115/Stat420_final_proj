---
title: "Predict Prices for Your Dream House"
author: "STAT 420, Summer 2019, Zhenzhou Yang (zy29), Swan Htun (swanh2), Mike Kramer (mkramer4)"
date: '7/16/2019'
output:
  html_document: 
    toc: yes
  pdf_document: default
urlcolor: cyan
---

# Introduction

## Overview

In this project, we plan to find a suitable linear model to predict the prices of residential houses locating in Ames, Iowa, based on their attributes provided. This model is meaningful that the customers who want to buy a new house may rely on it to have a rough estimation. 

In this project, many of the topics will be included, some of them will be:

- Multiple linear regression
- Outlier diagnostics
- Model building 
- Model selection

## Dataset Introduction

### Source

The `Ames Housing dataset` we use in this project is provided by Dean De Cock from Truman State University for [`Kaggle competition`](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data).

### Introduction

The origin dataset mainly includes the sale of individual residential houses in Ames, Iowa from 2006 to 2010. 

It contains 2919 observations with 23 nominal, 23 ordinal, 14 discrete and 20 continuous variables, which are directly related to property sales. And we just use half of it which contains 1460 observations and split the data by half into our train and test dataset.

In our project, we choose the variables which we think have significant influence in affecting the price of a house to somplify the data and try to reduce the collinearity between different predictors at beginning:

- **SalePrice**: the property's sale price in dollars. This is our target to predict.
- **LotArea**: Lot size in square feet.
- **MSZoning**: Identifies the general zoning classification of the sale. It has following types:
  - A:	Agriculture
  - C:	Commercial
  - FV:	Floating Village Residential
  - I:	Industrial
  - RH:	Residential High Density
  - RL:	Residential Low Density
  - RP:	Residential Low Density Park 
  - RM:	Residential Medium Density
- **LotShape**: General shape of property. It has the following levels:
  - Reg:	Regular	
  - IR1:	Slightly irregular
  - IR2:	Moderately Irregular
  - IR3:	Irregular
- **OverallQual**: Overall material and finish quality. It is an ordinal categorical variable range from 1 to 10 in origin data, which indicating the quality from very poor to very excellent.
- **YearBuilt**: Original construction date.
- **TotalBsmtSF**: Total square feet of basement area.
- **LowQualFinSF**: Low quality finished square feet (all floors).
- **BedroomAbvGr**: Bedrooms above grade (does NOT include basement bedrooms).
- **FullBath**: Full bathrooms above grade.
- **GarageArea**: Size of garage in square feet.

### Data

In this section, we will take a look at the data which has been modified by us for the project.

- Train data
```{r,message=FALSE}
library(readr)
data_raw = read_csv("house price.csv")

# split the data
train_idx = sample(1 : nrow(data_raw), nrow(data_raw) / 2)
test_idx = setdiff(seq(1 : nrow(data_raw)), train_idx)

train_raw = data_raw[train_idx,]
test_raw = data_raw[test_idx,]

# select variables we want to use
train = subset(train_raw, select = c("SalePrice", "LotArea", "MSZoning", "LotShape", "OverallQual", "YearBuilt", "TotalBsmtSF", "LowQualFinSF", "BedroomAbvGr", "FullBath", "GarageArea"))

# show a few lines
head(train, 5)

# let's take a galance at the response variable
head(train$SalePrice, 10)
```

- Test data
```{r,message=FALSE} 
# select variables we want to use
test = subset(test_raw, select = c("SalePrice", "LotArea", "MSZoning", "LotShape", "OverallQual", "YearBuilt", "TotalBsmtSF", "LowQualFinSF", "BedroomAbvGr", "FullBath", "GarageArea"))

# show a few lines
head(test, 5)

# let's take a galance at the response variable
head(test$SalePrice, 10)
```


# Methods

- The training data will be used for all model fitting. Our goal is to find a model that is useful for predicting house prices. We will begin with 2 multiple linear regression models where the first will be the addictive model and the second will account for all the two-way interactions between each predictors. 

- We will utilize methods learnt from class, such as backward search AIC and BIC, to see which predictors should be included. 

- We will also check for collinearity issues with the variables selected to avoid including variables that are highly correlated and thus, will cause high variance inflation factor. 

- We will also compare the adjusted R-squared values as well as LOOCV-RMSE of our models.

- Then, we will use the selected model to predict the house prices and check the results of our predictions. 


```{r}
str(train)
#change character varaibles to factor variables. 
train$LotShape = as.factor(train$LotShape)
train$MSZoning = as.factor(train$MSZoning)

test$LotShape = as.factor(test$LotShape)
test$MSZoning = as.factor(test$MSZoning)
```

```{r}
#check all the character variables are now factors.
str(train)
```

```{r}
levels(train$LotShape)
levels(train$MSZoning)
```

**Variable & Model Selection**

- Checking for collinearity issues using pair plots.

```{r}
library(faraway)
pairs(train, col = "dodgerblue")
```

- We can see that the factor variables 'LotShape' and 'MSZoning' don't display high correlation with any other variables so we are justified in removing these variables to calculate the correlation cofficient matrix and variance inflation factors. 


- Correlation cofficient pair plots without factor variables. 

```{r}
train1 = subset(train_raw, select = c("SalePrice", "LotArea", "OverallQual", "YearBuilt", "TotalBsmtSF", "LowQualFinSF", "BedroomAbvGr", "FullBath", "GarageArea"))

pairs(train1, col = "dodgerblue")
```

- Correlation coefficients & variance inflation factor

```{r}
train1 = subset(train_raw, select = c("SalePrice", "LotArea", "OverallQual", "YearBuilt", "TotalBsmtSF", "LowQualFinSF", "BedroomAbvGr", "FullBath", "GarageArea"))

(corr_coef = round(cor(train1), 4))
```


### Models

```{r}
full_add_model = lm(SalePrice ~ ., data = train)
full_2int_model = lm(SalePrice ~ . ^2, data = train)
```

- AIC Backward Search Selection

```{r}
aic_add_selected = step(full_add_model, trace = FALSE)
```

```{r}
aic_2int_selected = step(full_2int_model, trace = FALSE)
```

- BIC Backward Search Selection

```{r}
bic_add_selected = step(full_add_model, k = log(nrow(train)), trace = FALSE)
```

```{r}
bic_2int_selected = step(full_2int_model, k = log(nrow(train)), trace = FALSE)
```

- Exhaustive Search (maybe we can try this since other searches are kind of giving weird results)

```{r}
 library(leaps)
all_house_mod = summary(regsubsets(SalePrice ~ ., data = train))

all_house_mod$rss

all_house_mod$adjr2
```


- Calculate VIF of each of the models selected from the backward AIC and BIC search.

```{r, warning= FALSE}
vif_full = vif(full_add_model)
vif_2int = vif(full_2int_model)

length(coef(full_2int_model))
length(coef(full_add_model))

vif(full_add_model)[which.max(vif(full_add_model))]
vif(full_2int_model)[which.max(vif(full_2int_model))]
```


```{r, warning = FALSE}
vif_aic_add = vif(aic_add_selected)
vif_aic_2int = vif(aic_2int_selected)

length(coef(aic_add_selected))
length(coef(aic_2int_selected))

vif(aic_add_selected)[which.max(vif(aic_add_selected))]
vif(aic_2int_selected)[which.max(vif(aic_2int_selected))]

```


```{r, warning=FALSE}
vif_bic_add = vif(bic_add_selected)
vif_bic_2int = vif(bic_2int_selected)

length(coef(bic_add_selected))
length(coef(bic_2int_selected))

vif(bic_add_selected)[which.max(vif(bic_add_selected))]
vif(bic_2int_selected)[which.max(vif(bic_2int_selected))]

```

**LOOCV_RMSE**

```{r}
#function to calculate LOOCV_RMSE
calc_loocv_rmse = function(model) { 
   sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}
```

- Calculate the LOOCV_RMSE of each model.
```{r}
calc_loocv_rmse(full_add_model)
calc_loocv_rmse(full_2int_model)

calc_loocv_rmse(aic_add_selected)
calc_loocv_rmse(aic_2int_selected)

calc_loocv_rmse(bic_add_selected)
calc_loocv_rmse(bic_2int_selected)
```

**Adjusted R-squared**
```{r}
summary(full_add_model)$adj
summary(full_2int_model)$adj

summary(aic_add_selected)$adj
summary(aic_2int_selected)$adj

summary(bic_add_selected)$adj
summary(bic_2int_selected)$adj
```

**Average Percent Error**

```{r}
#function to calculate average percent error
get_perc_err = function(actual, predicted) {
  100 * mean((abs(actual - predicted)) / actual)
}

```

